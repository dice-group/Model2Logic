{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d6a59d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv as cv\n",
    "from joblib import load, dump\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d2e3fa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ConvertDNN2logic:\n",
    "    \n",
    "    def __init__(self, image_data=False):\n",
    "        with open('param_dict.csv') as csv_file:\n",
    "            reader = cv.reader(csv_file)\n",
    "            self.paramDict = dict(reader) \n",
    "        if self.paramDict['multi_label'] == 'True':\n",
    "            self.dnn = load('Model/dnn_model_multi.joblib') \n",
    "        else:\n",
    "            self.dnn = load('Model/dnn_model')\n",
    "        self.df = pd.read_csv('AdultMod.csv')\n",
    "        self.no_of_params = int(self.paramDict['no_of_params'])    \n",
    "        self.no_of_hidden_layer = len(self.dnn.coefs_) -1\n",
    "        self.num_weight_vector = len(self.dnn.coefs_)\n",
    "        #self.no_of_layer = len(self.dnn.linears)\n",
    "        self.no_of_class = self.dnn.n_outputs_\n",
    "        \n",
    "        \n",
    "    def remove_exponent(self, value):\n",
    "        if 'e-' in value:\n",
    "            decial = value.split('e')\n",
    "            ret_val = format(((float(decial[0]))*(10**int(decial[1]))), '.5f')\n",
    "            return ret_val\n",
    "        else: \n",
    "            return value\n",
    "\n",
    "    def funcDNN2logic(self):\n",
    "        with open('feNameType.csv') as csv_file:\n",
    "            reader = cv.reader(csv_file)\n",
    "            feName_type = dict(reader)\n",
    "        f=open('DNNSmt1.smt2', 'w')\n",
    "        f.write(';Input layer neurons \\n')\n",
    "        for i in range(0, self.no_of_params):\n",
    "            f.write(';-----------'+str(i)+'th parameter----------------- \\n')\n",
    "            #Initializing input features\n",
    "            for j in range(0, self.dnn.n_features_in_):\n",
    "                f.write('(declare-fun '+self.df.columns.values[j]+str(i)+' ()')\n",
    "                if('int' in str(self.df.dtypes[j])):\n",
    "                    f.write(' Int) \\n')\n",
    "                else:\n",
    "                    f.write(' Real) \\n')\n",
    "                #f.write('(assert (and (>= '+self.df.columns.values[j]+str(i)+' 0) (<= '+self.df.columns.values[j]+str(i)\n",
    "                #    +' 1))) \\n')\n",
    "                \n",
    "                            \n",
    "            #Initializing hidden layer neurons\n",
    "            for j in range(0, self.num_weight_vector-1):\n",
    "                for k in range(0, len(self.dnn.coefs_[j][0])):\n",
    "                    f.write('(declare-fun nron'+str(j)+str(k)+str(i)+' () Real) \\n')\n",
    "                    f.write('(declare-fun tmp'+str(j)+str(k)+str(i)+' () Real) \\n')\n",
    "            #Initializing output neurons\n",
    "            for j in range(0, self.no_of_class):\n",
    "                f.write('(declare-fun y'+str(j)+str(i)+' () Real) \\n')\n",
    "                f.write('(declare-fun tmp'+str(self.no_of_hidden_layer)+str(j)+str(i)+' () Real) \\n')\n",
    "            #Initializing extra variables needed for encoding argmax \n",
    "            '''\n",
    "            for j in range(0, self.no_of_class):\n",
    "                for k in range(0, self.no_of_class):\n",
    "                    f.write('(declare-fun d'+str(j)+str(k)+str(i)+' () Int) \\n')\n",
    "            '''\n",
    "            if(self.paramDict['multi_label'] == 'FALSE'):\n",
    "                if self.paramDict['regression'] == 'no':\n",
    "                    f.write('(declare-fun Class'+str(i)+' () Int) \\n')\n",
    "                else:\n",
    "                    f.write('(declare-fun Class' + str(i) + ' () Real) \\n')\n",
    "                    #f.write('(assert (and (>= Class'+str(i)+' 0) (<= Class'+str(i)+' 1))) \\n')\n",
    "\n",
    "            else:\n",
    "                for j in range(0, self.no_of_class):\n",
    "                    class_name = self.df.columns.values[self.df.shape[1]-self.no_of_class+j]\n",
    "                    f.write('(declare-fun '+class_name+str(i)+' () Int) \\n')\n",
    "                    f.write('(assert (and (>= '+class_name+str(i)+' 0) (<= '+class_name+str(i)+' 1))) \\n')\n",
    "    \n",
    "        f.write('(define-fun absoluteInt ((x Int)) Int \\n')\n",
    "        f.write('  (ite (>= x 0) x (- x))) \\n')\n",
    "        f.write('(define-fun absoluteReal ((x Real)) Real \\n')\n",
    "        f.write('  (ite (>= x 0) x (- x))) \\n')  \n",
    "\n",
    "    \n",
    "        for i in range(0, self.no_of_params):\n",
    "            f.write(';-----------'+str(i)+'th parameter----------------- \\n')\n",
    "            f.write('\\n ;Encoding the hidden layer neurons \\n')\n",
    "            for j in range(0, self.no_of_hidden_layer):\n",
    "                for k in range(0, len(self.dnn.coefs_[j][0])):\n",
    "                    f.write('(assert (= ')\n",
    "                    f.write('tmp'+str(j)+str(k)+str(i)+' (+')\n",
    "                    for l in range(0, len(self.dnn.coefs_[j])):\n",
    "                        #temp_val = round(float(self.dnn.linears[j].weight[k][l]), 5)\n",
    "                        temp_val = format(self.dnn.coefs_[j][l][k], '.5f')\n",
    "                        if('e' in str(temp_val)):\n",
    "                            temp_val = self.remove_exponent(str(temp_val))\n",
    "                        if j == 0:\n",
    "                            f.write('(* '+self.df.columns.values[l]+str(i)+' '+str(temp_val)+')')\n",
    "                        else:\n",
    "                            f.write('(* nron'+str(j-1)+str(l)+str(i)+' '+str(temp_val)+') ')\n",
    "                    #temp_bias = round(float(self.dnn.linears[j].bias[k]), 5)\n",
    "                    temp_bias = format(self.dnn.intercepts_[j][k], '.5f')\n",
    "                    if('e' in str(temp_bias)):\n",
    "                        temp_bias = self.remove_exponent(str(temp_bias))\n",
    "                    f.write(str(temp_bias)+'))) \\n')\n",
    "\n",
    "                    f.write('(assert (or ')                   \n",
    "                    f.write(' (and (> tmp'+str(j)+str(k)+str(i)+' 0) (= nron'+str(j)+str(k)+str(i)+\n",
    "                           ' tmp'+str(j)+str(k)+str(i)+'))')\n",
    "                    f.write(' (and (<= tmp'+str(j)+str(k)+str(i)+' 0) (= nron'+str(j)+str(k)+str(i)+\n",
    "                           ' 0)))) \\n')\n",
    "            \n",
    "            f.write('\\n ;Encoding the output layer neuron \\n')           \n",
    "            for j in range(0, self.dnn.n_outputs_):\n",
    "                f.write('(assert (= tmp'+str(self.no_of_hidden_layer)+str(j)+str(i)+' (+ ')\n",
    "                for k in range(0, len(self.dnn.coefs_[self.no_of_hidden_layer-1][0])):\n",
    "                    #temp_val = round(float( self.dnn.linears[self.no_of_layer-1].weight[j][k]), 5)\n",
    "                    temp_val = format(self.dnn.coefs_[self.no_of_hidden_layer][k][j], '.5f')\n",
    "                    if('e' in str(temp_val)):\n",
    "                        temp_val = self.remove_exponent(str(temp_val))\n",
    "                    f.write('(* nron'+str(self.no_of_hidden_layer-1)+str(k)+str(i)+' '+str(temp_val)+')')\n",
    "                #temp_bias = round(float(self.dnn.linears[self.no_of_layer-1].bias[j]), 5)\n",
    "                temp_bias = format(self.dnn.intercepts_[self.no_of_hidden_layer][j], '.5f')\n",
    "                if('e' in str(temp_bias)):\n",
    "                    temp_bias = self.remove_exponent(str(temp_bias))\n",
    "                f.write(' '+str(temp_bias)+'))) \\n')\n",
    "                #f.write('(assert (or ')\n",
    "                f.write('(assert (= y'+str(j)+str(i)+' tmp'+str(self.no_of_hidden_layer)+str(j)+str(i)+'))\\n ')\n",
    "                #f.write(' (and (<= tmp'+str(self.no_of_hidden_layer)+str(j)+str(i)+' 0) (= y'+str(j)+str(i)+\n",
    "                #           ' 0)))) \\n')\n",
    "                          \n",
    "            f.write('\\n ;Encoding argmax constraint \\n')\n",
    "            if self.paramDict['regression'] == 'no':\n",
    "                if self.paramDict['multi_label'] == 'FALSE':\n",
    "                    f.write('(assert (or \\n')\n",
    "                    if self.no_of_class != 1:\n",
    "                        for j in range(0, self.no_of_class):\n",
    "                            f.write(' (and (and ')\n",
    "                            for k in range(0, self.no_of_class):\n",
    "                                if(j != k):\n",
    "                                    f.write('(>= y'+str(j)+str(i)+' y'+str(k)+str(i)+')')\n",
    "                            f.write(') (= Class'+str(i)+' '+str(j)+'))\\n')  \n",
    "                        f.write('))\\n')    \n",
    "                    else:\n",
    "                        f.write('(and (>= y00 0.5) (= Class'+str(i)+' 0)) (and (< y00 0.5) (= Class'+str(i)+' 1))')\n",
    "                        f.write('))\\n')\n",
    "                else:\n",
    "                    for j in range(0, self.no_of_class):\n",
    "                        class_name = self.df.columns.values[self.df.shape[1]-self.no_of_class+j]\n",
    "                        f.write('(assert (=> (> y'+str(j)+str(i)+' 0.5) (= '+class_name+str(i)+' 1))) \\n')\n",
    "            else:\n",
    "                f.write('(assert (= Class'+str(i)+' y0'+str(i)+')) \\n')\n",
    "\n",
    "        f.write('(assert (= Class0 1))\\n')\n",
    "        f.write('(check-sat) \\n(get-model)\\n')\n",
    "        f.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c87ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d8841f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_check = ConvertDNN2logic()\n",
    "obj_check.funcDNN2logic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "5ac003df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnab\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Model/dnn_model']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "\n",
    "df = pd.read_csv('AdultMod.csv')\n",
    "data = df.values\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "lyer_size = [2,2,2]\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=lyer_size).fit(X, y)\n",
    "dump(clf, 'Model/dnn_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "6b2bbb0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.03644204,  0.01173329],\n",
       "        [ 0.03262706, -0.01977428],\n",
       "        [-0.04003809, -0.36166727],\n",
       "        [-0.07670319, -0.18160118],\n",
       "        [-0.47244254, -0.05162379],\n",
       "        [-0.11573691,  0.44937642],\n",
       "        [ 0.41542476,  0.35073316],\n",
       "        [ 0.29387234, -0.24845806],\n",
       "        [ 0.17868867, -0.10934153],\n",
       "        [-0.06404566,  0.39384596],\n",
       "        [-0.02181637, -0.22491413],\n",
       "        [ 0.43301789,  0.1267593 ]]),\n",
       " array([[-1.12641351, -0.87910961],\n",
       "        [-0.37969789, -0.68872402]]),\n",
       " array([[ 0.0953533 , -0.70552404],\n",
       "        [ 0.90370788,  0.66889302]]),\n",
       " array([[ 1.18767514e+00,  8.68225140e-01, -7.82552187e-02],\n",
       "        [ 9.48787684e-04,  6.80171427e-01,  5.05313061e-02]])]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coefs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "acf3480d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.86308697, -0.00689382])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coefs_[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d791d9",
   "metadata": {},
   "source": [
    "clf.n_outputs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ec45cebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55382292, 0.35099321, 0.09518387]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba([[30,7,13,4,1,1,4,1,0,0,40,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "765a6ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[30,7,13,4,1,1,4,1,0,0,40,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c21b7b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.428072223041856"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6688628485029.0/15625000000000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "33fbf675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'softmax'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.out_activation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4c920c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39458676073677157"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "1/(1+math.exp(0.428072223041856))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b814a389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22827794 0.41796594 0.35375612]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each row of x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))  # subtract the max for numerical stability\n",
    "    return e_x / e_x.sum(axis=0)  # axis=0 to sum over columns\n",
    "\n",
    "scores = np.array([ -306636859.0/500000000.0, -4218851.0/500000000.0,  -438074723.0/2500000000.0])\n",
    "probs = softmax(scores)\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c50fc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(assert (and (= Age0 30) (= Workclass0 7) (= Education0 13) (= MaritalStatus0 4) (= Occupation0 1) (= Relationship0 1) (= Race0 4) (= Sex0 1)\n",
    "(= Capital-gain0 0) (= Capital-loss0 0) (= hours-per-week0 40) (= NativeCountry0 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "98009074",
   "metadata": {},
   "outputs": [],
   "source": [
    "paraDict = {}\n",
    "paraDict['la'] = [1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "134b9735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv as cv\n",
    "with open('trial.csv', 'w', newline='') as csv_file:\n",
    "    writer = cv.writer(csv_file)\n",
    "    for key, value in paraDict.items():\n",
    "        writer.writerow([key, value])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ba446815",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trial.csv') as csv_file:\n",
    "    reader = cv.reader(csv_file)\n",
    "    mydict = dict(reader)\n",
    "lyer = eval(mydict['la'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ab420488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b6f792c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a69235a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
